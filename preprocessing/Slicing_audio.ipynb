{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df147a0",
   "metadata": {},
   "source": [
    "# Sliging\n",
    "하나의 오디오 파일을 일정 구간별로 자릅니다.\n",
    "realtime으로 오디오를 입력받을 때 오디오를 일정 구간의 buffer로 나누어 받습니다.\n",
    "이를 학습 과정에서도 동일하게 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06220fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b7a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. nr, trimming\n",
    "# 2. slicing in to 64ms or 128ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40d41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_and_trimming(file):\n",
    "\n",
    "    audio_data, sample_rate = librosa.load(file, 16000)\n",
    "    \n",
    "\n",
    "    # noise reduction\n",
    "    noisy_part = audio_data[0:10000]\n",
    "    reduced_noise = nr.reduce_noise(y=audio_data, y_noise=noisy_part, sr=16000)\n",
    "\n",
    "\n",
    "    # trimming. 무음구간을 제거합니다.\n",
    "    trimmed, index = librosa.effects.trim(reduced_noise, top_db=5, hop_length=256, frame_length=512)\n",
    "\n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa162b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8115\n"
     ]
    }
   ],
   "source": [
    "# speaking data trimming\n",
    "\n",
    "speaking_path = r'./Dataset_audio/Speaking/'\n",
    "speaking_trimmed_path = os.path.join(speaking_path,'trimmed')\n",
    "\n",
    "for file in os.listdir(speaking_path + 'RIR/'):\n",
    "    if file.endswith('.wav') | file.endswith('.WAV'):\n",
    "        trimmed = nr_and_trimming(os.path.join(speaking_path, 'RIR', file))\n",
    "        sf.write(os.path.join(speaking_trimmed_path, file.split('.')[-2]+'_trimmed.wav'), trimmed, 16000, format='wav')\n",
    "        \n",
    "print(len(os.listdir(speaking_trimmed_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e4a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8015\n"
     ]
    }
   ],
   "source": [
    "# OtherSound(non-speaking) data trimming\n",
    "\n",
    "OtherSound_path = r'./Dataset_audio/OtherSound/'\n",
    "OtherSound_trimmed_path = os.path.join(noise_path,'trimmed')\n",
    "\n",
    "for file in os.listdir(OtherSound_path + 'RIR/'):\n",
    "    if file.endswith('.wav') | file.endswith('.WAV'):\n",
    "        trimmed = nr_and_trimming(os.path.join(OtherSound_path, 'RIR', file))\n",
    "        sf.write(os.path.join(OtherSound_trimmed_path, file.split('.')[-2]+'_trimmed.wav'), trimmed, 16000, format='wav')\n",
    "        \n",
    "print(len(os.listdir(OtherSound_trimmed_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13afddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49808\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "from pydub import AudioSegment\n",
    "speaking_path = r'./Dataset_audio/Speaking/'\n",
    "# Slicing unit\n",
    "MS = 256\n",
    "\n",
    "speaking_trimmed_path = os.path.join(speaking_path + 'trimmed')\n",
    "speaking_sliced_path = os.path.join(speaking_path + 'sliced')\n",
    "\n",
    "\n",
    "for file in os.listdir(speaking_trimmed_path):\n",
    "    trimmed = AudioSegment.from_wav(os.path.join(speaking_trimmed_path, file))\n",
    "    if len(trimmed) >= 1024: # filtering too short files\n",
    "        for i in range(0, len(trimmed), MS):\n",
    "            trimmed[i:i+MS].export(os.path.join(speaking_sliced_path, file.split('.')[-2]+str(i)+'_sliced.wav'), format='wav')\n",
    "\n",
    "print(len(os.listdir(speaking_sliced_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b81e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128201\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "\n",
    "# Slicing unit\n",
    "MS = 256 # 256ms\n",
    "OtherSound_path = r'./Dataset_audio/OtherSound'\n",
    "OtherSound_trimmed_path = os.path.join(OtherSound_path, 'trimmed')\n",
    "OtherSound_sliced_path = os.path.join(OtherSound_path, 'sliced')\n",
    "\n",
    "\n",
    "for file in os.listdir(OtherSound_trimmed_path):\n",
    "    trimmed = AudioSegment.from_wav(os.path.join(OtherSound_trimmed_path, file))\n",
    "    if len(trimmed) >= 1024:                                \n",
    "        for i in range(0, len(trimmed), MS):\n",
    "            trimmed[i:i+MS].export(os.path.join(OtherSound_sliced_path, file.split('.')[-2]+str(i)+'_sliced.wav'), format='wav')\n",
    "\n",
    "print(len(os.listdir(OtherSound_sliced_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419a5697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78393"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balancing. 데이터 간 균형을 맞춰줍니다.\n",
    "filenum_diff = len(os.listdir(speaking_sliced_path)) - len(os.listdir(OtherSound_sliced_path))\n",
    "filenum_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fcf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "erase_files = random.sample(os.listdir(OtherSound_sliced_path), abs(filenum_diff))\n",
    "\n",
    "for file in os.listdir(OtherSound_sliced_path): # or speaking_sliced_path\n",
    "    if file in erase_files:\n",
    "        os.remove(os.path.join(OtherSound_sliced_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5818f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(speaking_sliced_path)) == len(os.listdir(OtherSound_sliced_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd914e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49808"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(OtherSound_sliced_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.5",
   "language": "python",
   "name": "venv3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
